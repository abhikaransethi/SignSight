{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ecc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2b2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d0c89b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8, maxHands=2)\n",
    " \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img=cv2.flip(img, 1)\n",
    "#     hands, img = detector.findHands(img)  # With Draw\n",
    "    hands = detector.findHands(img, draw=False)  # No Draw\n",
    " \n",
    "    if hands:\n",
    "        # Hand 1\n",
    "        hand1 = hands[0]\n",
    "        \n",
    "        bbox1 = hand1[\"bbox\"]  # Bounding Box info x,y,w,h\n",
    "        \n",
    "        centerPoint1 = hand1[\"center\"]  # center of the hand cx,cy\n",
    "        handType1 = hand1[\"type\"]  # Hand Type Left or Right\n",
    " \n",
    "        # print(len(lmList1),lmList1)\n",
    "        # print(bbox1)\n",
    "        # print(centerPoint1)\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "        #length, info, img = detector.findDistance(lmList1&#91;8], lmList1&#91;12], img) # with draw\n",
    "        #length, info = detector.findDistance(lmList1&#91;8], lmList1&#91;12])  # no draw\n",
    " \n",
    "        bbox=bbox1\n",
    "        if len(hands) == 2:\n",
    "            hand2 = hands[1]\n",
    "            \n",
    "            bbox2 = hand2[\"bbox\"]  # Bounding Box info x,y,w,h\n",
    "            \n",
    "            centerPoint2 = hand2[\"center\"]  # center of the hand cx,cy\n",
    "            handType2 = hand2[\"type\"]  # Hand Type Left or Right\n",
    " \n",
    "            fingers2 = detector.fingersUp(hand2)\n",
    "            # print(fingers1, fingers2)\n",
    "            #length, info, img = detector.findDistance(lmList1&#91;8], lmList2&#91;8], img) # with draw\n",
    "            bbox=[min(bbox1[0], bbox2[0]), min(bbox1[1],bbox2[1]), bbox1[2]+bbox2[2]+20, max(bbox1[3],bbox2[3])+20]\n",
    "        startx=0\n",
    "        starty=0\n",
    "        endx=img.shape[1]\n",
    "        endy=img.shape[0]\n",
    "        \n",
    "        if bbox[1] - 20>=0:\n",
    "            starty=bbox[1] - 20\n",
    "        if bbox[1] + bbox[3] + 20<endy:\n",
    "            endy=bbox[1] + bbox[3] + 20\n",
    "        if bbox[0] - 20>=0:\n",
    "            startx=bbox[0] - 20\n",
    "        if bbox[0] + bbox[2] + 20<endx:\n",
    "            endx=bbox[0] + bbox[2] + 20\n",
    "        \n",
    "        \n",
    "        crop_img = img[starty:endy, startx: endx]\n",
    "        cv2.rectangle(img, (bbox[0] - 20, bbox[1] - 20), (bbox[0] + bbox[2] + 20, bbox[1] + bbox[3] + 20), (0,255,0),3)\n",
    "       \n",
    "#         print(crop_img.shape)\n",
    "        \n",
    "        # res=cv2.flip(res,1)\n",
    "        out=image_preprocessing_and_prediction(crop_img)\n",
    "        \n",
    "        cv2.putText(img, out, (bbox[0] - 20, bbox[1] - 20), cv2.FONT_HERSHEY_COMPLEX, 3, (0,0,255), 10)\n",
    "        \n",
    "        \n",
    "\n",
    "    # applying gaussian blur\n",
    "#         value = (35, 35)\n",
    "#         blurred = cv2.GaussianBlur(grey, value, 0)\n",
    "\n",
    "#         # thresholdin: Otsu's Binarization method\n",
    "#         _, thresh1 = cv2.threshold(blurred, 127, 255,\n",
    "#                                    cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "#         # show thresholded image\n",
    "#         cv2.imshow('Thresholded1', thresh1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         \n",
    "            \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.imshow(\"Image\", img)\n",
    "#     if hands:\n",
    "#         cv2.imshow(\"Frame\", crop_img)\n",
    "    \n",
    "    cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "# vs.stream.release()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e92a3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing_and_prediction(res):\n",
    "\n",
    "  res=cv2.resize(res,(32,32))\n",
    "  # res=cv2.cvtColor(res, cv2.COLOR_GRAY2RGB)\n",
    "  test_image = image.img_to_array(res)\n",
    "  test_image = np.expand_dims(test_image, axis = 0)\n",
    "  test_image=test_image.astype('float32')/255.0\n",
    "  result = loaded_model.predict(test_image)\n",
    "  x=result.tolist()[0]\n",
    "  indexes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K','L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V','W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\n",
    "  return indexes[x.index(max(x))]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e67b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "(1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(\"1.jpeg\")\n",
    "frame2=cv2.resize(frame,(32,32))\n",
    "test_image = image.img_to_array(frame2)\n",
    "print(test_image.shape)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "print(test_image.shape)\n",
    "# test_image = test_image.astype('float32')\n",
    "\n",
    "test_image=test_image.astype('float32')/255.0\n",
    "\n",
    "result = loaded_model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38229a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n"
     ]
    }
   ],
   "source": [
    "x=result.tolist()[0]\n",
    "indexes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K','L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V','W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\n",
    "print(indexes[x.index(max(x))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74bd3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e027b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open(\"model-bw-asl.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(model_json)\n",
    "loaded_model.load_weights(\"model-bw-asl.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd6904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
