{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ecc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2b2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0c89b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8, maxHands=2)\n",
    "           \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img=cv2.flip(img, 1)\n",
    "#   hands, img = detector.findHands(img)  # With Draw\n",
    "    hands = detector.findHands(img, draw=False)  # No Draw\n",
    "                \n",
    "    if hands:   \n",
    "        # Hand 1  \n",
    "        hand1 = hands[0]\n",
    "                    \n",
    "        bbox1 = hand1[\"bbox\"]  # Bounding Box info x,y,w,h\n",
    "                    \n",
    "        centerPoint1 = hand1[\"center\"]  # center of the hand cx,cy\n",
    "        handType1 = hand1[\"type\"]  \n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "        #length, info, img = detector.findDistance(lmList1&#91;8], lmList1&#91;12], img) # with draw\n",
    "        #length, info = detector.findDistance(lmList1&#91;8], lmList1&#91;12])  # no draw\n",
    "                    \n",
    "        bbox=bbox1  \n",
    "        if len(hands) == 2:\n",
    "            hand2 = hands[1]\n",
    "                     \n",
    "            bbox2 = hand2[\"bbox\"]  # Bounding Box info x,y,w,h\n",
    "                     \n",
    "            centerPoint2 = hand2[\"center\"]  # center of the hand cx,cy\n",
    "            handType2 = hand2[\"type\"]  # Hand Type Left or Right\n",
    "                     \n",
    "            fingers2 = detector.fingersUp(hand2)\n",
    "            # print(fingers1, fingers2)\n",
    "            #length, info, img = detector.findDistance(lmList1&#91;8], lmList2&#91;8], img) # with draw\n",
    "            bbox=[min(bbox1[0], bbox2[0]), min(bbox1[1],bbox2[1]), bbox1[2]+bbox2[2]+20, max(bbox1[3],bbox2[3])+20]\n",
    "        startx=0     \n",
    "        starty=0\n",
    "        endx=img.shape[1]\n",
    "        endy=img.shape[0]\n",
    "        \n",
    "        if bbox[1] - 20>=0:\n",
    "            starty=bbox[1] - 20\n",
    "        if bbox[1] + bbox[3] + 20<endy:\n",
    "            endy=bbox[1] + bbox[3] + 20\n",
    "        if bbox[0] - 20>=0:\n",
    "            startx=bbox[0] - 20\n",
    "        if bbox[0] + bbox[2] + 20<endx:\n",
    "            endx=bbox[0] + bbox[2] + 20\n",
    "        \n",
    "        \n",
    "        crop_img = img[starty:endy, startx: endx]\n",
    "        cv2.rectangle(img, (bbox[0] - 20, bbox[1] - 20), (bbox[0] + bbox[2] + 20, bbox[1] + bbox[3] + 20), (0,255,0),3)\n",
    "        \n",
    "#         print(crop_img.shape)\n",
    "        grey = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(grey, (5,5),2)\n",
    "        th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "        \n",
    "        ret, res = cv2.threshold(th3, 70, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        # res=cv2.flip(res,1)\n",
    "        out=image_preprocessing_and_prediction(res)\n",
    "        \n",
    "        cv2.putText(img, out, (bbox[0] - 20, bbox[1] - 20), cv2.FONT_HERSHEY_COMPLEX, 3, (0,0,255), 10)\n",
    "        cv2.imshow('Thresholded', res)  \n",
    "            \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.imshow(\"Image\", img)\n",
    "#     if hands:\n",
    "#         cv2.imshow(\"Frame\", crop_img)\n",
    "    \n",
    "    cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "# vs.stream.release()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92a3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing_and_prediction(res):\n",
    "\n",
    "  res=cv2.resize(res,(100,100))\n",
    "  # res=cv2.cvtColor(res, cv2.COLOR_GRAY2RGB)\n",
    "  test_image = image.img_to_array(res)\n",
    "  test_image = np.expand_dims(test_image, axis = 0)\n",
    "  \n",
    "  result = loaded_model.predict(test_image)\n",
    "  x=result.tolist()[0]\n",
    "  indexes=['1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "  return indexes[x.index(max(x))]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e67b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n",
      "(1, 100, 100, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6112/3958854453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# test_image=test_image/255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(\"1.jpeg\")\n",
    "frame2=cv2.resize(frame,(100,100))\n",
    "gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(gray,(5,5),2)\n",
    "minValue=70\n",
    "th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "ret, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "res=cv2.cvtColor(res, cv2.COLOR_GRAY2BGR)\n",
    "test_image = image.img_to_array(res)\n",
    "print(test_image.shape)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "print(test_image.shape)\n",
    "# test_image = test_image.astype('float32')\n",
    "\n",
    "# test_image=test_image/255.0\n",
    "\n",
    "result = loaded_model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38229a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74bd3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e027b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open(\"model-bw.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(model_json)\n",
    "loaded_model.load_weights(\"model-bw.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd6904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
